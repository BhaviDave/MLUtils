{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "yr9tjdfJ_KnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LhuMukhz_DTR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer, Normalizer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "!pip install --quiet optuna\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "yq1yFFyR_m94"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "pPnnDp_LJRbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  encode a categorical column based on the mean of the target column.\n",
        "def target_encode(cat_column, target_column, train , valid, test):\n",
        "    mean_target = train.groupby(cat_column)[target_column].mean()\n",
        "    train_encoded_series = train[cat_column].map(mean_target)\n",
        "    valid_encoded_series = valid[cat_column].map(mean_target)\n",
        "    test_encoded_series = test[cat_column].map(mean_target)\n",
        "    return train_encoded_series , valid_encoded_series, test_encoded_series"
      ],
      "metadata": {
        "id": "tsFwexg7JSiI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return variables that are correlated beyond thresh - drop one of the two variables\n",
        "def highly_corr(df, thresh= 0.8):\n",
        "  corrmat = df.corr()\n",
        "  upper_tri = corrmat.where(np.triu(np.ones(corrmat.shape),k=1).astype(bool))\n",
        "  to_drop = [column for column in upper_tri.columns if any(upper_tri[column] >thresh)]\n",
        "  return to_drop"
      ],
      "metadata": {
        "id": "wA9G7t6VJSgk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set extreme outliers equal to a specified percentile of the data\n",
        "def winsorize_data( columns, train, valid, test, lower_percentile=5, upper_percentile=95):\n",
        "\n",
        "    for col in columns:\n",
        "        lower_limit = np.percentile(train[col], lower_percentile)\n",
        "        upper_limit = np.percentile(train[col], upper_percentile)\n",
        "        train[col] = np.where(train[col] < lower_limit, lower_limit,\n",
        "                                      np.where(train[col] > upper_limit, upper_limit, train[col]))\n",
        "        valid[col] = np.where(valid[col] < lower_limit, lower_limit,\n",
        "                                      np.where(valid[col] > upper_limit, upper_limit, valid[col]))\n",
        "        test[col] = np.where(test[col] < lower_limit, lower_limit,\n",
        "                                      np.where(test[col] > upper_limit, upper_limit, test[col]))\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "CKgeZ0dfaiDX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_null_values(df , mean_impute = False):\n",
        "  if mean_impute:\n",
        "    return df.fillna(df.mean()) #Fill missing values with column mean\n",
        "  else:\n",
        "    return df.dropna().reset_index() # Remove rows with null values\n"
      ],
      "metadata": {
        "id": "imuhNf7pgQIy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method - Interquartile Range (IQR)\n",
        "def get_outliers(df , col , alpha = 1.5):\n",
        "  Q1 = df[col].quantile(0.25)\n",
        "  Q3 = df[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower_bound = Q1 - alpha * IQR\n",
        "  upper_bound = Q3 + alpha * IQR\n",
        "  outliers_iqr = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "  return len(outliers_iqr) , outliers_iqr.index"
      ],
      "metadata": {
        "id": "aeCjOTKpjAV1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def info(df):\n",
        "  print('-----------------------------------------------------------')\n",
        "  print('Column wise null counts : ')\n",
        "  null_counts = df.isnull().sum()\n",
        "  print(null_counts)\n",
        "\n",
        "  print('-----------------------------------------------------------')\n",
        "  rows_with_null = df.isnull().any(axis=1).sum()\n",
        "  print(\"Number of rows with at least one null value: \", rows_with_null)\n",
        "\n",
        "  print('-----------------------------------------------------------')\n",
        "  print('Unique Values per column : ')\n",
        "  print(df.nunique())\n"
      ],
      "metadata": {
        "id": "CwmAXH2mJSep"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outliers_info(df, numerical):\n",
        "  out = {}\n",
        "  for col in numerical:\n",
        "    l , _ = get_outliers(df , col )\n",
        "    out[col] = l\n",
        "  return out"
      ],
      "metadata": {
        "id": "TifwEubikTWQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_metrics(y, predict):\n",
        "  print('-----------------------------------------------------------')\n",
        "  r_2 = r2_score( y, predict)\n",
        "  mse = mean_squared_error(y, predict)\n",
        "  rmse = math.sqrt(mse)\n",
        "  print('r2 ', r_2)\n",
        "  print('mse ', mse)\n",
        "  print('rmse ', rmse)\n",
        "  print('-----------------------------------------------------------')\n"
      ],
      "metadata": {
        "id": "8IxXreUIxWIW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "zvGVEytZ_Sw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/HousingData.csv',  delimiter=',')"
      ],
      "metadata": {
        "id": "NIotFycl_SX5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
        "       'PTRATIO', 'B', 'LSTAT']\n",
        "categorical = ['CHAS']\n",
        "target = 'MEDV'"
      ],
      "metadata": {
        "id": "msBWttVtIT2D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5epu7gDPhh6I",
        "outputId": "c8daba93-b7ab-40b3-e1ef-4213acb87dc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "Column wise null counts : \n",
            "CRIM       20\n",
            "ZN         20\n",
            "INDUS      20\n",
            "CHAS       20\n",
            "NOX         0\n",
            "RM          0\n",
            "AGE        20\n",
            "DIS         0\n",
            "RAD         0\n",
            "TAX         0\n",
            "PTRATIO     0\n",
            "B           0\n",
            "LSTAT      20\n",
            "MEDV        0\n",
            "dtype: int64\n",
            "-----------------------------------------------------------\n",
            "Number of rows with at least one null value:  112\n",
            "-----------------------------------------------------------\n",
            "Unique Values per column : \n",
            "CRIM       484\n",
            "ZN          26\n",
            "INDUS       76\n",
            "CHAS         2\n",
            "NOX         81\n",
            "RM         446\n",
            "AGE        348\n",
            "DIS        412\n",
            "RAD          9\n",
            "TAX         66\n",
            "PTRATIO     46\n",
            "B          357\n",
            "LSTAT      438\n",
            "MEDV       229\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_info(df, numerical + [target])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glUAb8HudJPe",
        "outputId": "1e093836-79ba-40c4-863f-7b56a8f39922"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CRIM': 65,\n",
              " 'ZN': 63,\n",
              " 'INDUS': 0,\n",
              " 'NOX': 0,\n",
              " 'RM': 30,\n",
              " 'AGE': 0,\n",
              " 'DIS': 5,\n",
              " 'RAD': 0,\n",
              " 'TAX': 0,\n",
              " 'PTRATIO': 15,\n",
              " 'B': 77,\n",
              " 'LSTAT': 7,\n",
              " 'MEDV': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_temp, test = train_test_split(df,  test_size=0.2, random_state=42)\n",
        "train, valid = train_test_split(train_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "del train_temp"
      ],
      "metadata": {
        "id": "2zH6memYdQp-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = handle_null_values(train), handle_null_values(valid), handle_null_values(test)"
      ],
      "metadata": {
        "id": "B-dQBe4Yhndp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target encode categorical variables\n",
        "for cat in categorical :\n",
        "  train[cat + '_target_encode'],  valid[cat + '_target_encode'], test[cat + '_target_encode'] = target_encode( cat, target, train, valid, test)\n",
        "  train.drop(cat , axis = 1, inplace = True)\n",
        "  valid.drop(cat , axis = 1, inplace = True)\n",
        "  test.drop(cat , axis = 1, inplace = True)\n",
        "  numerical.append(cat + '_target_encode')"
      ],
      "metadata": {
        "id": "7v5W-RbAIVR3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop highly correlated variables\n",
        "to_drop = highly_corr(train[numerical])\n",
        "for d in to_drop:\n",
        "  train.drop(d , axis = 1, inplace = True)\n",
        "  valid.drop(d , axis = 1, inplace = True)\n",
        "  test.drop(d , axis = 1, inplace = True)\n",
        "  numerical.remove(d)"
      ],
      "metadata": {
        "id": "RF2qYKvPQByz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = winsorize_data(['CRIM','ZN', 'RM' , 'B', 'MEDV'], train, valid, test)"
      ],
      "metadata": {
        "id": "6_LwkcCDVsBd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , y_train = train[numerical], train[target]\n",
        "X_valid , y_valid = valid[numerical], valid[target]\n",
        "X_test , y_test = test[numerical], test[target]"
      ],
      "metadata": {
        "id": "aPULZTkqSCaY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# todo scale data"
      ],
      "metadata": {
        "id": "W9K_DM_qqVZp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit_transform(X_valid)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "VkTlEwoSqVSv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Models train"
      ],
      "metadata": {
        "id": "lZOZ8u02myV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "  regressor = trial.suggest_categorical(\"regressor\", [# \"LinearRegression\", \"Ridge\", \"Lasso\"\n",
        "                                                      \"GradientBoostingRegressor\",\n",
        "                                                      \"RandomForestRegressor\",\n",
        "                                                      \"XGBRegressor\"])\n",
        "\n",
        "  if regressor == \"GradientBoostingRegressor\":\n",
        "     params = {\n",
        "              'n_estimators' : trial.suggest_int(\"n_estimators\", 2, 20),\n",
        "              'max_depth' : trial.suggest_int(\"max_depth\", 1, 32),\n",
        "              'learning_rate' : trial.suggest_float(\"learning_rate\", 1e-7, 0.3, log=True),\n",
        "              'random_state' : 42,\n",
        "              'min_samples_split' : trial.suggest_int(\"min_samples_split\", 10, 32)\n",
        "              }\n",
        "     clf = GradientBoostingRegressor(**params)\n",
        "\n",
        "  elif regressor == \"RandomForestRegressor\":\n",
        "     params = {\n",
        "            \"n_estimators\":  trial.suggest_int(\"n_estimators\", 2, 20),\n",
        "            \"max_depth\":  trial.suggest_int(\"max_depth\", 1, 32),\n",
        "            # \"max_features\": trial.suggest_categorical( \"max_features\", choices=[\"auto\", \"sqrt\", \"log2\"] ),\n",
        "            \"random_state\": 42,\n",
        "             'min_samples_split' : trial.suggest_int(\"min_samples_split\", 10, 32)\n",
        "            }\n",
        "     clf = GradientBoostingRegressor(**params)\n",
        "\n",
        "  elif regressor == \"XGBRegressor\":\n",
        "     params = {\n",
        "              'n_estimators' : trial.suggest_int(\"n_estimators\", 2, 20),\n",
        "              'max_depth' : trial.suggest_int(\"max_depth\", 1, 32),\n",
        "              'learning_rate' : trial.suggest_float(\"learning_rate\", 1e-7, 0.3, log=True),\n",
        "              'random_state' : 42\n",
        "              }\n",
        "\n",
        "     clf = XGBRegressor(**params)\n",
        "\n",
        "  if clf == 'XGBRegressor' :\n",
        "    clf.fit(X_train, y_train, early_stopping_rounds=10,\n",
        "               eval_set =[X_valid, y_valid])\n",
        "  else:\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "  predict = clf.predict(X_valid)\n",
        "\n",
        "  r_2 = r2_score( y_valid, predict)\n",
        "\n",
        "  mse = mean_squared_error(y_valid, predict)\n",
        "  rmse = math.sqrt(mse)\n",
        "\n",
        "  return rmse\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=100,  timeout=600)\n",
        "\n",
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg88TS3WcAhX",
        "outputId": "1f49c949-100a-4bd3-d101-1408c09bde22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-10 22:08:58,264] A new study created in memory with name: no-name-2fd0990e-ac2f-4bd8-af6f-d1b2c63c72a9\n",
            "[I 2024-04-10 22:08:58,442] Trial 0 finished with value: 3.022606805315279 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 27, 'min_samples_split': 29}. Best is trial 0 with value: 3.022606805315279.\n",
            "[I 2024-04-10 22:08:59,030] Trial 1 finished with value: 7.521926751516057 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 18, 'max_depth': 14, 'learning_rate': 2.726466904408726e-05}. Best is trial 0 with value: 3.022606805315279.\n",
            "[I 2024-04-10 22:08:59,072] Trial 2 finished with value: 2.7213099962514287 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 8, 'learning_rate': 0.2122614196838708, 'min_samples_split': 32}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,089] Trial 3 finished with value: 4.600346849230843 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 6, 'max_depth': 21, 'min_samples_split': 23}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,120] Trial 4 finished with value: 7.524905647392589 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 14, 'max_depth': 8, 'learning_rate': 1.7440211485116617e-07, 'min_samples_split': 10}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,162] Trial 5 finished with value: 7.520317040495934 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 12, 'max_depth': 8, 'learning_rate': 6.328915820013222e-05}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,191] Trial 6 finished with value: 7.524412305373216 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 12, 'max_depth': 23, 'learning_rate': 6.231206498034924e-06, 'min_samples_split': 21}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,209] Trial 7 finished with value: 7.517663578291975 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 6, 'max_depth': 29, 'learning_rate': 0.00017429125729168338, 'min_samples_split': 16}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,235] Trial 8 finished with value: 7.52469387383606 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 2, 'max_depth': 17, 'learning_rate': 1.862465882487891e-05}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,246] Trial 9 finished with value: 7.4845149732043454 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 2, 'max_depth': 20, 'learning_rate': 0.002982835784597557, 'min_samples_split': 22}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,291] Trial 10 finished with value: 3.4405297056932627 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 16, 'max_depth': 2, 'learning_rate': 0.2276074866534951, 'min_samples_split': 32}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,356] Trial 11 finished with value: 2.986107557836357 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 32, 'min_samples_split': 32}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,416] Trial 12 finished with value: 2.9907791352657522 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 32, 'min_samples_split': 28}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,468] Trial 13 finished with value: 3.2161712108593514 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 16, 'max_depth': 11, 'min_samples_split': 32}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,514] Trial 14 finished with value: 2.985166276643388 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 17, 'max_depth': 4, 'min_samples_split': 27}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,554] Trial 15 finished with value: 3.699621851418817 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 16, 'max_depth': 1, 'learning_rate': 0.1543097854054352, 'min_samples_split': 26}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,591] Trial 16 finished with value: 3.987096373688937 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 9, 'max_depth': 5, 'min_samples_split': 27}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,670] Trial 17 finished with value: 2.8477324286275807 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 6, 'min_samples_split': 25}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,744] Trial 18 finished with value: 7.056836456466263 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 9, 'max_depth': 12, 'learning_rate': 0.007833900523699675, 'min_samples_split': 17}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:08:59,949] Trial 19 finished with value: 6.849629904403987 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 14, 'max_depth': 9, 'learning_rate': 0.008320294273617152}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,016] Trial 20 finished with value: 3.295718462881142 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 14, 'max_depth': 15, 'min_samples_split': 24}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,071] Trial 21 finished with value: 2.938336344558744 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 5, 'min_samples_split': 29}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,124] Trial 22 finished with value: 2.974633111235807 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 5, 'min_samples_split': 30}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,179] Trial 23 finished with value: 2.7234074501710595 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 6, 'min_samples_split': 25}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,251] Trial 24 finished with value: 3.142650142492609 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 11, 'min_samples_split': 18}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,316] Trial 25 finished with value: 7.417397583684674 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 9, 'learning_rate': 0.000811954391540708, 'min_samples_split': 25}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,369] Trial 26 finished with value: 3.0934688073088217 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 7, 'min_samples_split': 19}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,415] Trial 27 finished with value: 3.211193831718944 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 15, 'max_depth': 3, 'min_samples_split': 13}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,515] Trial 28 finished with value: 7.524804195168522 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 19, 'max_depth': 13, 'learning_rate': 1.0341883328488465e-06}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,581] Trial 29 finished with value: 4.5370011977850835 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 19, 'max_depth': 6, 'learning_rate': 0.03469286967536872, 'min_samples_split': 20}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,636] Trial 30 finished with value: 3.182812586427692 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 16, 'max_depth': 17, 'min_samples_split': 24}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,680] Trial 31 finished with value: 4.11397811577631 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 1, 'min_samples_split': 31}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,728] Trial 32 finished with value: 2.9907622865986907 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 4, 'min_samples_split': 29}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,781] Trial 33 finished with value: 3.134398439754053 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 17, 'max_depth': 10, 'min_samples_split': 30}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,838] Trial 34 finished with value: 2.8705604046364246 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 6, 'min_samples_split': 26}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,894] Trial 35 finished with value: 2.9750130123215506 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 7, 'min_samples_split': 25}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:00,987] Trial 36 finished with value: 7.402393944781164 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 20, 'max_depth': 15, 'learning_rate': 0.001014975064949101}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,101] Trial 37 finished with value: 5.468347519227922 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 17, 'max_depth': 7, 'learning_rate': 0.02256974688026895, 'min_samples_split': 22}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,190] Trial 38 finished with value: 3.502243072154558 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 13, 'max_depth': 3, 'min_samples_split': 27}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,288] Trial 39 finished with value: 7.504236085182225 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 11, 'max_depth': 9, 'learning_rate': 0.00028183101685466775, 'min_samples_split': 24}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,344] Trial 40 finished with value: 5.386135837926051 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 4, 'max_depth': 24, 'min_samples_split': 26}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,432] Trial 41 finished with value: 2.8638801915150593 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 5, 'min_samples_split': 29}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,520] Trial 42 finished with value: 2.9472025452964585 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 7, 'min_samples_split': 29}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,602] Trial 43 finished with value: 3.028736355840088 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 28}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,837] Trial 44 finished with value: 4.09391903727799 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 17, 'max_depth': 6, 'learning_rate': 0.05325017649693803}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:01,941] Trial 45 finished with value: 2.909475263968519 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 9, 'min_samples_split': 22}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,023] Trial 46 finished with value: 7.524764499724303 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 15, 'max_depth': 13, 'learning_rate': 1.6146955732106314e-06, 'min_samples_split': 31}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,131] Trial 47 finished with value: 3.0364496528336193 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 19, 'min_samples_split': 26}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,205] Trial 48 finished with value: 3.4868508282274617 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 2, 'min_samples_split': 28}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,310] Trial 49 finished with value: 7.524909734739097 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 17, 'max_depth': 8, 'learning_rate': 1.111956546678322e-07, 'min_samples_split': 23}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,389] Trial 50 finished with value: 4.691079303134943 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 6, 'max_depth': 11, 'min_samples_split': 31}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,483] Trial 51 finished with value: 2.891456795136105 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 5, 'min_samples_split': 22}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,580] Trial 52 finished with value: 3.011662856151155 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 18, 'max_depth': 5, 'min_samples_split': 25}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,699] Trial 53 finished with value: 2.88709699118376 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 19, 'max_depth': 4, 'min_samples_split': 21}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,789] Trial 54 finished with value: 3.9895269245467544 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 20, 'max_depth': 1, 'min_samples_split': 20}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:02,871] Trial 55 finished with value: 3.1486546703992704 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 15, 'max_depth': 4, 'min_samples_split': 23}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:03,435] Trial 56 finished with value: 7.346291193321482 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 18, 'max_depth': 6, 'learning_rate': 0.0016652637552020443}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:03,499] Trial 57 finished with value: 3.5816442318538675 and parameters: {'regressor': 'RandomForestRegressor', 'n_estimators': 16, 'max_depth': 2, 'min_samples_split': 30}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:03,606] Trial 58 finished with value: 2.826795478075977 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 10, 'learning_rate': 0.26398359937991644, 'min_samples_split': 32}. Best is trial 2 with value: 2.7213099962514287.\n",
            "[I 2024-04-10 22:09:03,719] Trial 59 finished with value: 2.526600501104273 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 10, 'learning_rate': 0.2966738552456868, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:03,831] Trial 60 finished with value: 2.746913983918598 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 10, 'learning_rate': 0.23420171297936188, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:03,968] Trial 61 finished with value: 2.7853987301437577 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 10, 'learning_rate': 0.21930958726604027, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:04,249] Trial 62 finished with value: 2.8605188715886922 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.2750850997880551, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:04,469] Trial 63 finished with value: 3.167124478054976 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 10, 'learning_rate': 0.08197192496281189, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:04,733] Trial 64 finished with value: 2.796293134081294 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 9, 'max_depth': 14, 'learning_rate': 0.29059030190869695, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:04,926] Trial 65 finished with value: 2.905657674790931 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 8, 'max_depth': 15, 'learning_rate': 0.263622896860383, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:05,160] Trial 66 finished with value: 4.116439915867379 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 10, 'max_depth': 13, 'learning_rate': 0.0825167571234036, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:05,301] Trial 67 finished with value: 4.68297625254617 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 7, 'max_depth': 10, 'learning_rate': 0.08690177093171135, 'min_samples_split': 30}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:05,468] Trial 68 finished with value: 6.504606903399965 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 9, 'max_depth': 12, 'learning_rate': 0.019466904653380402, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:05,678] Trial 69 finished with value: 3.3646761545010637 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 11, 'max_depth': 14, 'learning_rate': 0.12420461404563277, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:05,937] Trial 70 finished with value: 2.8231846664686904 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 8, 'max_depth': 8, 'learning_rate': 0.2896866764482054, 'min_samples_split': 30}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:06,161] Trial 71 finished with value: 2.882251023570056 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 8, 'max_depth': 8, 'learning_rate': 0.26260832723932326, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:06,308] Trial 72 finished with value: 2.9157162519716686 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 7, 'max_depth': 11, 'learning_rate': 0.2897211176451512, 'min_samples_split': 30}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:06,458] Trial 73 finished with value: 5.369741941189078 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 8, 'max_depth': 8, 'learning_rate': 0.05231119064076446, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:06,642] Trial 74 finished with value: 4.493552206541509 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 5, 'max_depth': 10, 'learning_rate': 0.13401433165413756, 'min_samples_split': 30}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:06,852] Trial 75 finished with value: 3.8344179559219747 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 10, 'max_depth': 8, 'learning_rate': 0.0952605202164696, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:07,064] Trial 76 finished with value: 4.497496079674815 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 11, 'learning_rate': 0.03420106116990195, 'min_samples_split': 28}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:07,280] Trial 77 finished with value: 6.75666015731104 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 10, 'max_depth': 14, 'learning_rate': 0.01160160175335585, 'min_samples_split': 10}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:07,390] Trial 78 finished with value: 4.031093974257509 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 7, 'max_depth': 18, 'learning_rate': 0.12583692056264914, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:07,598] Trial 79 finished with value: 2.837294443592987 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 16, 'learning_rate': 0.15182584985491998, 'min_samples_split': 30}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:07,725] Trial 80 finished with value: 4.2989026444484875 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 12, 'max_depth': 9, 'learning_rate': 0.064296512764212, 'min_samples_split': 29}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:07,867] Trial 81 finished with value: 2.622079650594293 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 15, 'learning_rate': 0.29573953169405687, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:08,017] Trial 82 finished with value: 2.783839163047796 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.18301588863091744, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:08,125] Trial 83 finished with value: 2.6962404126352806 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 18, 'max_depth': 14, 'learning_rate': 0.15412289402117454, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:08,300] Trial 84 finished with value: 2.82081796154048 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 19, 'max_depth': 16, 'learning_rate': 0.12751659318318265, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:08,450] Trial 85 finished with value: 4.307099942079562 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 19, 'max_depth': 13, 'learning_rate': 0.040172254144298286, 'min_samples_split': 29}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:08,639] Trial 86 finished with value: 2.8722209951569897 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 18, 'max_depth': 12, 'learning_rate': 0.1467559559212041, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:08,886] Trial 87 finished with value: 7.517492769531552 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 20, 'max_depth': 14, 'learning_rate': 5.698127576515992e-05, 'min_samples_split': 32}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:09,003] Trial 88 finished with value: 5.713845328806414 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 18, 'max_depth': 21, 'learning_rate': 0.018703271981017542, 'min_samples_split': 31}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:09,124] Trial 89 finished with value: 6.971082747172209 and parameters: {'regressor': 'GradientBoostingRegressor', 'n_estimators': 19, 'max_depth': 18, 'learning_rate': 0.004351541988800372, 'min_samples_split': 14}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:10,521] Trial 90 finished with value: 2.7528115380578146 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 20, 'max_depth': 30, 'learning_rate': 0.1587715149842697}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:10,918] Trial 91 finished with value: 2.622977013692172 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.17127964545151203}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:11,747] Trial 92 finished with value: 2.7711832422544473 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.15678657212561112}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:12,163] Trial 93 finished with value: 3.7897573523042682 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 19, 'max_depth': 28, 'learning_rate': 0.05387356501519382}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:13,285] Trial 94 finished with value: 2.64665421501102 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 20, 'max_depth': 30, 'learning_rate': 0.15889237951976368}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:14,563] Trial 95 finished with value: 4.619581070134547 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 20, 'max_depth': 30, 'learning_rate': 0.033308889790263384}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:14,906] Trial 96 finished with value: 3.2848268251396586 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 19, 'max_depth': 30, 'learning_rate': 0.07196749666652001}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:15,475] Trial 97 finished with value: 2.775426333244042 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 17, 'max_depth': 25, 'learning_rate': 0.15585003476938694}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:15,941] Trial 98 finished with value: 3.06496194442896 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 18, 'max_depth': 31, 'learning_rate': 0.08900308246966236}. Best is trial 59 with value: 2.526600501104273.\n",
            "[I 2024-04-10 22:09:16,320] Trial 99 finished with value: 2.6737461397670264 and parameters: {'regressor': 'XGBRegressor', 'n_estimators': 19, 'max_depth': 28, 'learning_rate': 0.16964807324008938}. Best is trial 59 with value: 2.526600501104273.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 100\n",
            "Best trial:\n",
            "  Value: 2.526600501104273\n",
            "  Params: \n",
            "    regressor: GradientBoostingRegressor\n",
            "    n_estimators: 20\n",
            "    max_depth: 10\n",
            "    learning_rate: 0.2966738552456868\n",
            "    min_samples_split: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yv86x3Bfy6D4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name  = trial.params['regressor']\n",
        "trial.params.pop('regressor')\n",
        "params = trial.params\n",
        "\n",
        "if name == \"GradientBoostingRegressor\":\n",
        "    model = GradientBoostingRegressor(**params)\n",
        "elif name == \"RandomForestRegressor\":\n",
        "    model = GradientBoostingRegressor(**params)\n",
        "elif name == \"XGBRegressor\":\n",
        "    model = XGBRegressor(**params)"
      ],
      "metadata": {
        "id": "7F-gPxTtzM18"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(X_train , y_train)\n",
        "\n",
        "print('Train')\n",
        "predict = model.predict(X_train)\n",
        "evaluation_metrics(y_train, predict )\n",
        "\n",
        "print('Valid')\n",
        "predict = model.predict(X_valid)\n",
        "evaluation_metrics(y_valid, predict )\n",
        "\n",
        "print('Test')\n",
        "predict = model.predict(X_test)\n",
        "evaluation_metrics(y_test, predict )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFP2rcd_wt3v",
        "outputId": "68bce095-de2c-4fc5-b47d-d44b46c6438e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "-----------------------------------------------------------\n",
            "r2  0.9958805648084803\n",
            "mse  0.3017621393132329\n",
            "rmse  0.5493288080132271\n",
            "-----------------------------------------------------------\n",
            "Valid\n",
            "-----------------------------------------------------------\n",
            "r2  0.8868358629670514\n",
            "mse  6.383710092180364\n",
            "rmse  2.526600501104273\n",
            "-----------------------------------------------------------\n",
            "Test\n",
            "-----------------------------------------------------------\n",
            "r2  0.9115634456729633\n",
            "mse  5.434962727491185\n",
            "rmse  2.331300651458577\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization import plot_optimization_history\n",
        "\n",
        "plotly_config = {\"staticPlot\": True}\n",
        "fig = plot_optimization_history(study)\n",
        "# fig.show()\n",
        "fig.show(config=plotly_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "EfNnxH3turbQ",
        "outputId": "c9f2b69d-65a0-41e8-c568-cfb4f9876f17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"255d7658-f632-4303-97bc-a182e92a0ecd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"255d7658-f632-4303-97bc-a182e92a0ecd\")) {                    Plotly.newPlot(                        \"255d7658-f632-4303-97bc-a182e92a0ecd\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[3.022606805315279,7.521926751516057,2.7213099962514287,4.600346849230843,7.524905647392589,7.520317040495934,7.524412305373216,7.517663578291975,7.52469387383606,7.4845149732043454,3.4405297056932627,2.986107557836357,2.9907791352657522,3.2161712108593514,2.985166276643388,3.699621851418817,3.987096373688937,2.8477324286275807,7.056836456466263,6.849629904403987,3.295718462881142,2.938336344558744,2.974633111235807,2.7234074501710595,3.142650142492609,7.417397583684674,3.0934688073088217,3.211193831718944,7.524804195168522,4.5370011977850835,3.182812586427692,4.11397811577631,2.9907622865986907,3.134398439754053,2.8705604046364246,2.9750130123215506,7.402393944781164,5.468347519227922,3.502243072154558,7.504236085182225,5.386135837926051,2.8638801915150593,2.9472025452964585,3.028736355840088,4.09391903727799,2.909475263968519,7.524764499724303,3.0364496528336193,3.4868508282274617,7.524909734739097,4.691079303134943,2.891456795136105,3.011662856151155,2.88709699118376,3.9895269245467544,3.1486546703992704,7.346291193321482,3.5816442318538675,2.826795478075977,2.526600501104273,2.746913983918598,2.7853987301437577,2.8605188715886922,3.167124478054976,2.796293134081294,2.905657674790931,4.116439915867379,4.68297625254617,6.504606903399965,3.3646761545010637,2.8231846664686904,2.882251023570056,2.9157162519716686,5.369741941189078,4.493552206541509,3.8344179559219747,4.497496079674815,6.75666015731104,4.031093974257509,2.837294443592987,4.2989026444484875,2.622079650594293,2.783839163047796,2.6962404126352806,2.82081796154048,4.307099942079562,2.8722209951569897,7.517492769531552,5.713845328806414,6.971082747172209,2.7528115380578146,2.622977013692172,2.7711832422544473,3.7897573523042682,2.64665421501102,4.619581070134547,3.2848268251396586,2.775426333244042,3.06496194442896,2.6737461397670264],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[3.022606805315279,3.022606805315279,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.7213099962514287,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273,2.526600501104273],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"staticPlot\": true, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('255d7658-f632-4303-97bc-a182e92a0ecd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5BxUeqNwoWc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna.visualization.plot_slice(study)"
      ],
      "metadata": {
        "id": "VsakiQWXwPPg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna.visualization.plot_contour(study, params=[\"n_estimators\", \"max_depth\"])"
      ],
      "metadata": {
        "id": "7NDmuIwSwdNr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/bextuychiev/no-bs-guide-to-hyperparameter-tuning-with-optuna#Defining-the-search-space"
      ],
      "metadata": {
        "id": "EekJLOJkwkdd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# todo write cross val for smaller dataset"
      ],
      "metadata": {
        "id": "lgH_LdgH9nQw"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}